$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

experiment_name: codellama-codegen

settings:
  default_compute: azureml:gpu-epensive
  force_rerun: true
  continue_on_step_failure: false

inputs:
  # specify the foundation model available in the azureml system registry
  mlflow_model_path:
    path: azureml://registries/azureml-meta/models/CodeLlama-7b-hf/versions/3

  compute_model_import: gpu-expensive
  compute_preprocess: gpu-expensive
  compute_finetune: gpu-expensive
  compute_model_evaluation: gpu-expensive

  # map the dataset files to parameters
  train_file_path:
    type: uri_file
    # can't tell if we can actually just uploade from local?
    path: "../data/codellama_train.jsonl"
  validation_file_path:
    type: uri_file
    path: "../data/codellama_val.jsonl"
  test_file_path:
    type: uri_file
    path: "../data/codellama_test.jsonl"

  # The following parameters map to the dataset fields
  text_key: "docstring"
  ground_truth_key: "function"

  # training settings
  number_of_gpu_to_use_finetuning: 1
  num_train_epochs: 3
  per_device_train_batch_size: 5
  per_device_eval_batch_size: 5
  learning_rate: 2e-5

  # optimization params
  apply_lora: "true"
  apply_deepspeed: "true"
  apply_ort: "true"
  precision: 16

outputs:
  # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model
  # registering the model is required to deploy the model to an online or batch endpoint
  trained_model:
    type: mlflow_model

jobs:
  text_generation_pipeline:
    type: pipeline
    component: azureml://registries/azureml/components/text_generation_pipeline/labels/latest
    inputs:
      mlflow_model_path: ${{parent.inputs.mlflow_model_path}}

      compute_model_import: ${{parent.inputs.compute_model_import}}
      compute_preprocess: ${{parent.inputs.compute_preprocess}}
      compute_finetune: ${{parent.inputs.compute_finetune}}
      compute_model_evaluation: ${{parent.inputs.compute_model_evaluation}}

      train_file_path: ${{parent.inputs.train_file_path}}
      validation_file_path: ${{parent.inputs.validation_file_path}}
      test_file_path: ${{parent.inputs.test_file_path}}

      text_key: ${{parent.inputs.text_key}}
      ground_truth_key: ${{parent.inputs.ground_truth_key}}

      number_of_gpu_to_use_finetuning: ${{parent.inputs.number_of_gpu_to_use_finetuning}}
      num_train_epochs: ${{parent.inputs.num_train_epochs}}
      per_device_train_batch_size: ${{parent.inputs.per_device_train_batch_size}}
      per_device_eval_batch_size: ${{parent.inputs.per_device_eval_batch_size}}
      learning_rate: ${{parent.inputs.learning_rate}}
      apply_lora: ${{parent.inputs.apply_lora}}
      apply_deepspeed: ${{parent.inputs.apply_deepspeed}}
      apply_ort: ${{parent.inputs.apply_ort}}
      precision: ${{parent.inputs.precision}}

    outputs:
      mlflow_model_folder: ${{parent.outputs.trained_model}}
